  #Frequency at which jobs should listen for a kill signal
  AIRFLOW__SCHEDULER__JOB_HEARTBEAT_SEC=5
  #Frequency at which the scheduler should look to see if existing dags are schedulable
  AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=5
  #See: https://airflow.readthedocs.io/en/stable/best-practices.html#scheduler-uptime
  #As we are opting for a health check, we can set this to unlimited
  AIRFLOW__SCHEDULER__RUN_DURATION=-1
  #Frequency (in seconds) at which the scheduler should parse known dag files for updates
  AIRFLOW__SCHEDULER__PROCESSOR_POLL_INTERVAL=1
  #No additional delay to create a new dag once a new dag file is detected
  AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=0
  #Frequency (in seconds) at which the scheduler should scan the dags directory for new dag files
  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=60
  AIRFLOW__SCHEDULER__PRINT_STATS_INTERVAL=30
  #How long (in seconds) until last heartbeat before the scheduler be considered unhealthy
  AIRFLOW_SCHEDULER_HEALTH_CHECK_THRESHOLD=30
  AIRFLOW__SCHEDULER__CHILD_PROCESS_LOG_DIRECTORY=/opt/airflow/logs/scheduler
  #How long (in seconds) the scheduler should wait on a job that doesn't heartbeat before marking it as failed and re-scheduling it
  AIRFLOW__SCHEDULER__SCHEDULER_ZOMBIE_TASK_THRESHOLD=150
  #Disable catchup by default so as not to spam the queue. If a dag needs it, it can explicitly specify it.
  #Most probably won't.
  AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=False
  #Max batch size of db queries the scheduler makes.
  #Putting this value too high might overwelm the database.
  AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY=512
  #Number of paralell scheduler processes that should parse dags
  AIRFLOW__SCHEDULER__PARSING_PROCESSES=2
  #Scheduler should support scheduling jobs with cron
  AIRFLOW__SCHEDULER__USE_JOB_SCHEDULE=True
  #Keeping the default for this until we get a use-case
  AIRFLOW__SCHEDULER__ALLOW_TRIGGER_IN_FUTURE=False